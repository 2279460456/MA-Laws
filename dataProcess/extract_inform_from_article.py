import json
from tqdm import tqdm
import requests
import os
from docx import Document
 

url = "https://api.siliconflow.cn/v1/chat/completions"

def extract_case_info(case_text: str) -> dict:
    """
    ä»æ¡ˆä»¶æè¿°ä¸­æå– æ¡ˆä»¶æè¿°(case_description) å’Œ è¯æ®åº“ã€‚
    """
    if case_text == '':
        print("è¯¥æ¡ˆä»¶æ— è¾“å…¥")
        return False

    prompt = f"""
        ä½ æ˜¯ä¸€åæ³•å¾‹æ–‡ä¹¦ä¿¡æ¯æå–åŠ©æ‰‹ã€‚è¯·ä»ä»¥ä¸‹åˆ¤å†³ä¹¦æ–‡æœ¬ä¸­æå–å‡ºç»“æ„åŒ–å­—æ®µï¼Œå¹¶ä»¥ JSON æ ¼å¼è¾“å‡ºï¼Œä¸è¦è¾“å‡ºä¸­æ–‡å¤–çš„è¯­è¨€ã€‚

        æå–è¦æ±‚å¦‚ä¸‹ï¼š
        1. æ‰€æœ‰å­—æ®µå†…å®¹å¿…é¡»ä¸¥æ ¼æ¥æºäºåˆ¤å†³ä¹¦åŸæ–‡ï¼Œä¸å…è®¸è‡ªè¡Œæ¨æ–­ã€ç”Ÿæˆæˆ–è¡¥å……ã€‚
        2. è¯·ä¿æŒåŸå¥å®Œæ•´æ€§ï¼Œä¸å¾—æ”¹å†™åŸæ–‡ã€‚
        3. ä»…è¿”å›ä¸€ä¸ªåˆæ³•çš„ JSON å¯¹è±¡ï¼Œä¸è¦åŒ…å«ä»»ä½•é¢å¤–æ–‡å­—æˆ–æ³¨é‡Šã€‚

        éœ€è¦æå–çš„å­—æ®µåŠè¯´æ˜å¦‚ä¸‹ï¼š
        {{
            "CaseId": "å–è‡ªæ–‡ä¸­æ¡ˆå·ï¼Œä¾‹å¦‚'(2025)è¾½0911æ°‘åˆ3216å·'",
            "Fact": "æå–æ¡ˆä»¶äº‹å®ä¸ç»è¿‡éƒ¨åˆ†çš„å†…å®¹ï¼ŒåŒ…æ‹¬æ¡ˆä»¶çš„èµ·å› ã€å½“äº‹äººä¹‹é—´çš„å…³ç³»ã€äº‰è®®ç„¦ç‚¹ã€äº‹ä»¶ç»è¿‡åŠä¸»è¦è¯æ®ç­‰ã€‚ä»…ä¿ç•™å¯¹å®¢è§‚äº‹å®çš„æè¿°ï¼Œä¸åº”åŒ…å«æ³•é™¢æ¨ç†ã€è£åˆ¤é€»è¾‘ã€æ³•å¾‹æ¡æ–‡æˆ–æ¡æ¬¾å¼•ç”¨ç­‰å†…å®¹",
            "Reasoning": "æå–æ³•é™¢çš„æ¨ç†ä¸è£åˆ¤é€»è¾‘éƒ¨åˆ†ï¼ŒåŒ…æ‹¬æ³•é™¢å¯¹äº‹å®çš„è®¤å®šã€æ³•å¾‹æ¡æ–‡çš„é€‚ç”¨ã€äº‰è®®ç„¦ç‚¹çš„åˆ†æåŠåˆ¤å†³ç†ç”±ç­‰å†…å®¹ã€‚é¿å…æå–æ¡ˆä»¶äº‹å®æˆ–æœ€ç»ˆåˆ¤å†³ç»“æœ",
            "Judgment": "æå–æ³•é™¢çš„æœ€ç»ˆè£åˆ¤ç»“æœéƒ¨åˆ†ï¼ŒåŒ…æ‹¬åˆ¤å†³ä¸»æ–‡ã€è£å®šäº‹é¡¹æˆ–å¤„ç†ç»“æœç­‰å†…å®¹ï¼Œä½†ä¸åŒ…æ‹¬æ³•å®˜ç­¾åã€ä¹¦è®°å‘˜ä¿¡æ¯ç­‰",
            "Sentence": ["è‹¥æ¶‰åŠåˆ‘äº‹æ¡ˆä»¶çš„åˆ‘æœŸä¿¡æ¯ï¼Œå¦åˆ™ä¸ºç©ºæ•°ç»„"],
            "Fine": ["ç½šé‡‘ä¿¡æ¯ï¼Œå¦‚'ç½šé‡‘äººæ°‘å¸ä¸‰åƒå…ƒ'ï¼›å¦‚æ— ç½šé‡‘åˆ™ä¸ºç©ºæ•°ç»„"],
            "Crime Type": ["ç½ªåï¼Œå¦‚'å±é™©é©¾é©¶ç½ª'ï¼›å¦‚ç³»æ°‘äº‹æ¡ˆä»¶åˆ™ä¸ºç©ºæ•°ç»„"],
            "Law Articles": {{
                "ã€Šä¸­åäººæ°‘å…±å’Œå›½æ°‘æ³•å…¸ã€‹": ["æ¡å·åˆ—è¡¨ä½¿ç”¨çº¯é˜¿æ‹‰ä¼¯æ•°å­—ï¼Œä¾‹å¦‚ ['937','939','940','944']"],
                "ã€Šä¸­åäººæ°‘å…±å’Œå›½æ°‘äº‹è¯‰è®¼æ³•ã€‹": ["æ¡å·åˆ—è¡¨ä½¿ç”¨çº¯é˜¿æ‹‰ä¼¯æ•°å­—ï¼Œä¾‹å¦‚ ['147','260']"]
                â€”â€” å¦‚æœåˆ¤å†³ä¹¦ä¸­å¼•ç”¨äº†å…¶ä»–æ³•å¾‹ï¼Œè¯·åœ¨æ­¤å¯¹è±¡ä¸­ç»§ç»­åˆ—å‡ºç›¸åº”çš„æ³•å¾‹åç§°å’Œæ¡å·ï¼›
                â€”â€” è‹¥æ— å…¶ä»–æ³•å¾‹å¼•ç”¨ï¼Œåˆ™ä¸æ·»åŠ é¢å¤–é”®ã€‚
            }}
        }}

        ä»¥ä¸‹æ˜¯åˆ¤å†³ä¹¦å…¨æ–‡ï¼š
        {case_text}
        """

    payload = {
        "model": "deepseek-ai/DeepSeek-V3",
        "messages": [
            {
                "role": "user",
                "content": prompt
            }
        ],
        "stop": ["null"],
        "temperature": 0.7,
        "top_p": 0.7,
        "top_k": 50,
        "frequency_penalty": 0.5,
        "n": 1,
        "response_format": {"type": "text"},
        "tools": [
            {
                "type": "function",
                "function": {
                    "description": "<string>",
                    "name": "<string>",
                    "parameters": {},
                    "strict": False
                }
            }
        ]
    }

    headers = {
        "Authorization": "Bearer sk-cufzubuzkfsjdlxoybyusguhruyodkztslshwiuijdzgupeu",
        "Content-Type": "application/json"
    }

    response = requests.request("POST", url, json=payload, headers=headers)

    response_data = json.loads(response.text)
    content_string = response_data['choices'][0]['message']['content']

    # æ£€æŸ¥å¹¶ç§»é™¤å¼€å¤´çš„ "json\n" æˆ– "```json\n"ï¼Œä½¿ç”¨ä¸åŒçš„æ¨¡å‹ï¼Œæ¯ä¸ªæ¨¡å‹çš„å¼€å¤´ä¸ä¸€æ ·ï¼Œæ‰€ä»¥è¦åšå…¼å®¹æ€§å¤„ç†
    if content_string.strip().startswith("```json\n"): #é€‚ç”¨deepseek 
        content_string = content_string.strip()[len("```json\n"):].strip()
    elif content_string.strip().startswith("json\n"): #é€‚ç”¨Qwen 
        content_string = content_string.strip()[len("json\n"):].strip()

    # æ£€æŸ¥å¹¶ç§»é™¤æœ«å°¾çš„ "```"
    if content_string.strip().endswith("```"): #Deepseekåé¢ä¹Ÿæœ‰'```'ï¼Œæ‰€ä»¥è¦é™¤æ‰
        content_string = content_string.strip()[:-len("```")].strip()

    try:
        print(f'ans:\n:{content_string}')
        ans = json.loads(content_string)
    except json.JSONDecodeError as e:
        print(f"Error: æ— æ³•å°† content_string è§£æä¸º JSON: {e}")
        print(f"åŸå§‹ content_string: {content_string}")
        return {}
    
    return ans

def load_docx_context(input_file: str):
    """
    ä»docxåŠ è½½å†…å®¹
    """
    try:
        doc = Document(input_file)
        full_text = []

        # é€æ®µè¯»å–
        for para in doc.paragraphs:
            text = para.text.strip()
            if text:
                full_text.append(text)

        res = "\n".join(full_text)
        return res

    except Exception as e:
        print(f"âŒ è¯»å–å¤±è´¥ï¼š{input_file}\nåŸå› ï¼š{e}")
        return ""

def process_all_cases(input_dir, output_json_path):
    """
    æ‰¹é‡å¤„ç†æ–‡ä»¶å¤¹å†…æ‰€æœ‰docxæ–‡ä»¶ï¼Œæå–ç»“æ„åŒ–æ³•å¾‹æ–‡ä¹¦ä¿¡æ¯ï¼Œ
    æ”¯æŒæ–­ç‚¹ç»­è·‘ï¼ˆæŒ‰æ–‡ä»¶ååˆ¤æ–­ï¼‰ï¼Œå¹¶ä¿å­˜CaseIdä¾›åç»­æŸ¥é‡ã€‚
    """
    # Step 1. è¯»å–å†å²ç»“æœ
    if os.path.exists(output_json_path):
        with open(output_json_path, "r", encoding="utf-8") as f:
            try:
                results = json.load(f)
            except json.JSONDecodeError:
                results = []
    else:
        results = []

    # Step 2. å·²å¤„ç†æ–‡ä»¶é›†åˆï¼ˆæŒ‰æ–‡ä»¶ååˆ¤æ–­ï¼Œæœ€ç¨³å¦¥ï¼‰
    processed_files = {r.get("CaseName") for r in results if r.get("CaseName")}

    # Step 3. æ”¶é›†å…¨éƒ¨docxæ–‡ä»¶
    all_files = [
        os.path.join(input_dir, f)
        for f in os.listdir(input_dir)
        if f.endswith(".docx")
    ]

    print(f"ğŸ“ å…±æ£€æµ‹åˆ° {len(all_files)} ä¸ªå¾…å¤„ç†æ–‡ä»¶ã€‚")

    # Step 4. å¾ªç¯å¤„ç†
    for file_path in tqdm(all_files, desc="å¤„ç†ä¸­"):
        file_name = os.path.basename(file_path)

        # è·³è¿‡å·²å¤„ç†æ–‡ä»¶ï¼ˆæ–­ç‚¹ä¿æŠ¤ï¼‰,è°¨æ…ï¼Œä¸èƒ½å‡ºç°æ¡ˆä»¶åå®Œå…¨ä¸€è‡´çš„æ¡ˆå­ï¼Œå¦åˆ™ä¼šç›´æ¥è·³è¿‡ï¼Œä¸€èˆ¬ä¸ä¼šå‡ºç°ï¼Œå› ä¸ºåœ¨ä¸‹è½½æ–‡ä»¶æ—¶å¦‚æœæ–‡ä»¶åä¸€è‡´ä¼šè¦†ç›–æ‰æˆ–è€…æ–‡ä»¶ååé¢åŠ ä¸Šåºå·
        if file_name in processed_files:
            continue

        try:
            max_retries = 3  # æœ€å¤šå°è¯•3æ¬¡
            attempt = 0

            # è¯»å–ä¸æå–
            docx_context = load_docx_context(file_path)
            res = extract_case_info(docx_context)
            
            #æœ‰æ—¶å€™è¿”å›çš„resä¸ºç©º,æœ€å¤šè¿›è¡Œ3æ¬¡é‡æ–°æå–ï¼Œå¦‚æœè¿˜æ˜¯æ²¡æœ‰åˆ™è·³è¿‡è¯¥æ¡ˆä¾‹
            while('CaseId' not in res) and ( attempt < max_retries):
                attempt += 1
                print(f"âš ï¸ ç¬¬ {attempt} æ¬¡é‡è¯•æå– CaseId ...")
                res = extract_case_info(docx_context)

            # æ·»åŠ è¾…åŠ©ä¿¡æ¯
            res["Full Document"] = docx_context
            res["CaseName"] = file_name

            # å†™å…¥ç»“æœ
            results.append(res)
            processed_files.add(file_name)

            # å®æ—¶ä¿å­˜è¿›åº¦ï¼ˆé˜²æ­¢ä¸­æ–­ä¸¢å¤±ï¼‰
            with open(output_json_path, "w", encoding="utf-8") as f:
                json.dump(results, f, ensure_ascii=False, indent=4)

        except Exception as e:
            print(f"âŒ å¤„ç†æ–‡ä»¶å¤±è´¥ï¼š{file_path}\né”™è¯¯ä¿¡æ¯ï¼š{e}")
            continue

    print("âœ… å…¨éƒ¨å¤„ç†å®Œæˆï¼Œç»“æœå·²ä¿å­˜è‡³ï¼š", output_json_path)

if __name__ == "__main__":
    input_dir = "dataset/ministerCase/docx"
    output_json_path = "dataset/ministerCase/structured_results.json"
    process_all_cases(input_dir, output_json_path)




